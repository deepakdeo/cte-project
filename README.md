# ğŸ§  Character Traits Evaluator (CTE)

<p align="center">
  <img src="notebooks/reports/figures/cte_readme_overview.png" alt="CTE Overview" width="750">
</p>

---

## ğŸ¯ Project Overview

The **Character Traits Evaluator (CTE)** is a personal data-science and machine learning pipeline  
that analyzes **daily behavioral, physiological, and lifestyle metrics** to uncover how different  
habits influence **day-to-day productivity and well-being**.

This project represents a full **end-to-end ML workflow** â€” from raw data to predictive modeling â€”  
built entirely with open-source tools and designed for **reproducibility, interpretability,** and **portfolio readiness**.

---

## ğŸ§© Concept Pipeline

| Stage | Description | Techniques / Tools |
|:------|:-------------|:------------------|
| **Inputs** | 27 wearable and self-reported daily metrics (sleep, water, mood, study, etc.) | Data ingestion, preprocessing |
| **Analysis** | Exploratory Data Analysis (EDA), NLP on reflections, feature engineering, modeling | `pandas`, `numpy`, `matplotlib`, `scikit-learn` |
| **Outputs** | Insights on factors influencing productivity; correlation heatmaps, trendlines | Model evaluation, visualization |
| **Job-Fit Check** | (Planned) Compare trait patterns to job descriptions using LLMs | Embeddings, similarity modeling |

---

## ğŸ§ª Current Progress

| Notebook | Purpose | Key Outputs |
|-----------|----------|-------------|
| **`01_Preprocessing.ipynb`** | Cleaned and standardized daily logs (sleep, mood, hydration, study sessions) | `data/interim/cleaned.parquet` |
| **`02_Features.ipynb`** | Engineered ~100 quantitative and categorical features | `data/interim/features.parquet` |
| **`03_Baselines.ipynb`** | Built **time-aware regression baselines** predicting `productivity_pct` | `notebooks/reports/baseline_leaderboard.csv`, visual reports, model card |
| **`04_Modeling.ipynb`** *(in progress)* | Advanced models (XGBoost, LightGBM, feature lags, tuning) | â€” |
| **`05_Insights.ipynb`** *(planned)* | Explainable ML (SHAP) + visualization dashboard | â€” |

---

## ğŸ“Š Summary of Baseline Results

| Model | MAE | RMSE | RÂ² | Notes |
|:------|----:|----:|---:|:------|
| Mean Baseline | 52.5 | 57.9 | -0.93 | Reference |
| Ridge Regression | 43.2 | 50.8 | 0.25 | Improved linear baseline |
| **Gradient Boosting (depth 3)** | **41.0** | **48.5** | **0.42** | Best baseline model |

> *The best baseline model reduced RMSE by ~15â€“20 % compared to a naive mean predictor,  
> indicating clear predictive signal in the engineered daily features.*

---

## ğŸ“ˆ Outputs Generated

- ğŸ“„ **`baseline_leaderboard.csv`** â€” performance comparison table  
- ğŸ“Š **`/notebooks/reports/figures/`** â€” predicted vs true plots, residuals, feature importance  
- ğŸ§¾ **`baseline_modelcard.json`** â€” model metadata & reproducibility info  
- ğŸ’¾ **`/models/`** â€” persisted best baseline model (`.joblib`)

---

## ğŸ§° Tools & Techniques Demonstrated

| Category | Tools / Concepts |
|-----------|-----------------|
| **Data Wrangling** | `pandas`, `numpy`, datetime parsing, type handling |
| **Feature Engineering** | normalization, encoding, temporal variables |
| **Modeling** | regression (Linear, Ridge, RandomForest, GradientBoosting) |
| **Evaluation** | MAE, RMSE, RÂ², MAPE, expanding time-series CV |
| **Visualization** | `matplotlib`, correlation plots, residual analysis |
| **Automation & Reproducibility** | `pathlib`, modular directories, `Pipeline`, `joblib` |
| **Data Provenance** | JSON model cards, reproducible folder structure |

---

## ğŸ“ Repository Structure

```
cte-project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/               # Original daily logs
â”‚   â”œâ”€â”€ interim/           # Clean & feature-engineered data
â”‚   â””â”€â”€ processed/         # Modeling-ready data (future)
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_Preprocessing.ipynb
â”‚   â”œâ”€â”€ 02_Features.ipynb
â”‚   â”œâ”€â”€ 03_Baselines.ipynb
â”‚   â”œâ”€â”€ reports/
â”‚   â”‚   â”œâ”€â”€ figures/
â”‚   â”‚   â””â”€â”€ baseline_leaderboard.csv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ models/                # Saved models (.joblib)
â”œâ”€â”€ src/cte/               # Python modules and helpers
â””â”€â”€ pyproject.toml / .gitignore / README.md
```

---

## ğŸ”® Next Steps

- Add **temporal lag & rolling features** (yesterdayâ€™s productivity, 3-day moving averages)  
- Introduce **advanced models**: XGBoost, LightGBM, CatBoost  
- Perform **hyperparameter optimization** with `Optuna` or randomized search  
- Apply **SHAP** and **feature importance visualization** for interpretability  
- Build an interactive **Streamlit dashboard** for daily self-analytics  

---

## ğŸ‘¤ Author

**Deepak Kumar Deo**  
Ph.D. in Physics (Astrophysics) & Curriculum & Instruction  
ğŸ“ Kansas City, MO  
ğŸ’¼ Open to Data Scientist / Applied Scientist roles  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/deepakdeo) | [GitHub](https://github.com/deepakdeo)

---

### â­ Project Status
| Phase | Status | Description |
|:------|:------:|:------------|
| Data Cleaning & Features | âœ… | Complete |
| Baseline Modeling | âœ… | Complete |
| Advanced Modeling | ğŸš§ | In progress |
| Insights & Dashboard | â³ | Upcoming |

---

> _This project demonstrates end-to-end data-science fluency â€”  
> from real-world data collection to modeling, interpretation, and reporting â€”  
> built with clarity, reproducibility, and research-grade rigor._
