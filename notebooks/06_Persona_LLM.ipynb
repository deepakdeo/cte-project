{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d9a7a4d-1e7e-47e7-a73e-12d698232f95",
   "metadata": {},
   "source": [
    "# One-time Persona Synthesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcdc7b6-8b93-4ee2-968f-6f4d91c2ac7f",
   "metadata": {},
   "source": [
    "## 1) Setup & load artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44156d10-0825-45b5-8eba-ac920258ac8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 72 | Reflections with text: 72 | Figures found: 40\n"
     ]
    }
   ],
   "source": [
    "# -------- paths & env\n",
    "from pathlib import Path\n",
    "import os, json, re, base64, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "ROOT = Path.cwd()\n",
    "while not (ROOT/\"pyproject.toml\").exists() and ROOT.parent != ROOT:\n",
    "    ROOT = ROOT.parent\n",
    "\n",
    "DATA    = ROOT / \"data\" / \"interim\"\n",
    "REPORTS = ROOT / \"notebooks\" / \"reports\"\n",
    "FIGS    = REPORTS / \"figures\"\n",
    "for p in [REPORTS, FIGS]: p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# -------- load env (expects OPENAI_API_KEY)\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# -------- load core tables\n",
    "FEATURES = DATA / \"features.parquet\"\n",
    "assert FEATURES.exists(), f\"Missing {FEATURES}\"\n",
    "df = pd.read_parquet(FEATURES).sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "# use any precomputed trait CSV if you have it (optional but nice)\n",
    "hybrid_path = REPORTS/\"05_profile_traits_hybrid.csv\"\n",
    "hybrid = {}\n",
    "if hybrid_path.exists():\n",
    "    hybrid = pd.read_csv(hybrid_path, index_col=0).squeeze(\"columns\").to_dict()\n",
    "\n",
    "# reflections (raw; we’ll send full text)\n",
    "def clean_text(s):\n",
    "    if not isinstance(s, str): return \"\"\n",
    "    s = s.replace(\"\\n\",\" \").strip()\n",
    "    return re.sub(r\"\\s+\",\" \", s)\n",
    "\n",
    "ref = df.get(\"reflection\", pd.Series([\"\"]*len(df))).astype(str).apply(clean_text)\n",
    "\n",
    "# basic KPIs (feel free to extend)\n",
    "kpi = {\n",
    "    \"days\": int(len(df)),\n",
    "    \"reflections_with_text\": int(ref.str.len().gt(0).sum()),\n",
    "    \"avg_sleep_h\": float(df.get(\"sleep_duration_h\", pd.Series([np.nan]*len(df))).mean()),\n",
    "    \"sleep_std_h\": float(df.get(\"sleep_duration_h\", pd.Series([np.nan]*len(df))).std() or 0.0),\n",
    "    \"avg_productivity_pct\": float(df.get(\"productivity_pct\", pd.Series([np.nan]*len(df))).mean()),\n",
    "}\n",
    "\n",
    "# figures to include (you can include all; LLM calls will chunk automatically)\n",
    "figure_paths = sorted(FIGS.glob(\"*.png\"))\n",
    "\n",
    "print(f\"Rows: {len(df)} | Reflections with text: {kpi['reflections_with_text']} | Figures found: {len(figure_paths)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "999d3ca4-8c64-4830-b74d-34c130b47180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key detected ✅\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "assert os.getenv(\"OPENAI_API_KEY\"), \"Missing OPENAI_API_KEY\"\n",
    "print(\"API key detected ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe2e1447-9583-4600-a7a5-12383b01220e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key present?  True\n",
      "Prefix: sk-proj  length: 164\n",
      "After strip, length: 164\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# point explicitly at your repo root .env and override anything stale\n",
    "ROOT = Path.cwd()\n",
    "while not (ROOT/\"pyproject.toml\").exists() and ROOT.parent != ROOT:\n",
    "    ROOT = ROOT.parent\n",
    "load_dotenv(ROOT/\".env\", override=True)\n",
    "\n",
    "key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(\"Key present? \", bool(key))\n",
    "print(\"Prefix:\", (key or \"\")[:7], \" length:\", len(key or 0))\n",
    "\n",
    "# extra safety: strip hidden whitespace/newlines\n",
    "if key:\n",
    "    key = key.strip()\n",
    "    os.environ[\"OPENAI_API_KEY\"] = key\n",
    "    print(\"After strip, length:\", len(key))\n",
    "assert key and key.startswith(\"sk-\"), \"OPENAI_API_KEY missing or malformed\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cd845b-3a3e-449d-a891-d9cb675e40a1",
   "metadata": {},
   "source": [
    "## 2) Optional: sentiment/subjectivity (makes persona richer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccc48863-08c6-461e-8cd9-4a55fd9efaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "nltk.download(\"vader_lexicon\", quiet=True)\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "df[\"refl_sent_compound\"] = ref.apply(lambda t: sia.polarity_scores(t)[\"compound\"])\n",
    "df[\"refl_subjectivity\"]  = ref.apply(lambda t: TextBlob(t).sentiment.subjectivity)\n",
    "\n",
    "kpi.update({\n",
    "    \"avg_sentiment\": float(df[\"refl_sent_compound\"].mean()),\n",
    "    \"avg_subjectivity\": float(df[\"refl_subjectivity\"].mean())\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeefb208-7373-4dc6-8e7d-9f5b9d815b1f",
   "metadata": {},
   "source": [
    "## 3) OpenAI client + helpers (images, chunking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d2a03f2-8ed6-46fd-bc94-36f42590ac59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, re, base64\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def chat_json(system: str, user_text: str, model=\"gpt-4.1-mini\", max_tokens=1200):\n",
    "    \"\"\"\n",
    "    JSON-mode text-only call via Chat Completions (works with openai 2.7.1).\n",
    "    \"\"\"\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=0,\n",
    "        response_format={\"type\":\"json_object\"},\n",
    "        messages=[\n",
    "            {\"role\":\"system\",\"content\":system},\n",
    "            {\"role\":\"user\",\"content\":user_text},\n",
    "        ],\n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "    return resp.choices[0].message.content\n",
    "\n",
    "def chat_json_vision(system: str, text_prompt: str, images_b64: list, model=\"gpt-4o-mini\", max_tokens=800):\n",
    "    \"\"\"\n",
    "    JSON-mode vision call. images_b64 = [base64 strings for PNGs].\n",
    "    \"\"\"\n",
    "    content = [{\"type\":\"text\",\"text\":text_prompt}] + [\n",
    "        {\"type\":\"image_url\",\"image_url\":{\"url\":f\"data:image/png;base64,{b64}\"}} for b64 in images_b64\n",
    "    ]\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=0,\n",
    "        response_format={\"type\":\"json_object\"},\n",
    "        messages=[\n",
    "            {\"role\":\"system\",\"content\":system},\n",
    "            {\"role\":\"user\",\"content\":content},\n",
    "        ],\n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "    return resp.choices[0].message.content\n",
    "\n",
    "def encode_image_b64(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "def parse_json_maybe(s: str):\n",
    "    try:\n",
    "        return json.loads(s)\n",
    "    except Exception:\n",
    "        m = re.search(r\"\\{.*\\}\\s*$\", s, re.S)\n",
    "        return json.loads(m.group(0)) if m else {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb04f3a2-9b04-4e7f-beec-a0f0e08b1944",
   "metadata": {},
   "source": [
    "## 4) Map: analyze reflections in chunks (no hard cap; will batch automatically)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75542c94-67e9-4220-a833-9811311a7ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reflection chunks: 6 (size ~12)\n",
      "Mapped chunk 1/6\n",
      "Mapped chunk 2/6\n",
      "Mapped chunk 3/6\n",
      "Mapped chunk 4/6\n",
      "Mapped chunk 5/6\n",
      "Mapped chunk 6/6\n",
      "Saved maps -> /Users/deo/UMKC_phd/project_related/job_related/cte-project/notebooks/reports/06_persona_maps.json\n"
     ]
    }
   ],
   "source": [
    "# Build lines \"YYYY-MM-DD :: text\"\n",
    "lines = []\n",
    "for i, row in df.iterrows():\n",
    "    t = clean_text(row.get(\"reflection\", \"\"))\n",
    "    if t:\n",
    "        d = str(row.get(\"date\", \"\"))[:10]\n",
    "        lines.append(f\"{d} :: {t}\")\n",
    "\n",
    "chunk_size = 12  # reflections per chunk (adjust freely)\n",
    "chunks = [lines[i:i+chunk_size] for i in range(0, len(lines), chunk_size)]\n",
    "print(f\"Reflection chunks: {len(chunks)} (size ~{chunk_size})\")\n",
    "\n",
    "MAP_SYSTEM = (\n",
    "  \"You analyze daily reflections to extract behavioral traits relevant to work. \"\n",
    "  \"Return STRICT JSON with per-trait scores (0..1) and brief evidence quotes. Be concise, no biography.\"\n",
    ")\n",
    "\n",
    "TRAITS = [\n",
    "  \"focus\",\"reliability\",\"initiative\",\"communication\",\"adaptability\",\n",
    "  \"curiosity\",\"impact\",\"teamwork\",\"independence\",\"planning\",\n",
    "  \"resilience\",\"learning_mindset\"\n",
    "]\n",
    "\n",
    "MAP_SCHEMA = {\n",
    "  \"type\":\"object\",\n",
    "  \"properties\":{\n",
    "    \"per_trait\":{\n",
    "      \"type\":\"object\",\n",
    "      \"additionalProperties\":{\n",
    "        \"type\":\"object\",\n",
    "        \"properties\":{\n",
    "          \"score\":{\"type\":\"number\"},\n",
    "          \"confidence\":{\"type\":\"number\"},\n",
    "          \"evidence\":{\"type\":\"array\",\"items\":{\"type\":\"string\"}}\n",
    "        },\n",
    "        \"required\":[\"score\",\"confidence\"]\n",
    "      }\n",
    "    },\n",
    "    \"notes\":{\"type\":\"string\"}\n",
    "  },\n",
    "  \"required\":[\"per_trait\"]\n",
    "}\n",
    "\n",
    "map_outputs = []\n",
    "for idx, chunk in enumerate(chunks, 1):\n",
    "    # Assemble the user prompt for this chunk\n",
    "    text_block = \"Reflections (one per line):\\n\" + \"\\n\".join(chunk)\n",
    "    prompt = (\n",
    "      f\"{text_block}\\n\\n\"\n",
    "      f\"Trait set (score each 0..1): {TRAITS}\\n\"\n",
    "      f\"Schema (strict JSON):\\n{json.dumps(MAP_SCHEMA)}\"\n",
    "    )\n",
    "\n",
    "    # Chat Completions (JSON mode)\n",
    "    raw = chat_json(MAP_SYSTEM, prompt, model=\"gpt-4.1-mini\", max_tokens=1200)\n",
    "    js = parse_json_maybe(raw)\n",
    "    map_outputs.append(js)\n",
    "    print(f\"Mapped chunk {idx}/{len(chunks)}\")\n",
    "\n",
    "# Save map stage\n",
    "out_maps = REPORTS / \"06_persona_maps.json\"\n",
    "with open(out_maps, \"w\") as f:\n",
    "    json.dump(map_outputs, f, indent=2)\n",
    "print(\"Saved maps ->\", out_maps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5b1ba1-d206-4b42-b86a-537f4c39eba1",
   "metadata": {},
   "source": [
    "## 5) Figures → short bullets (vision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0aaac30c-178d-4c56-936c-6759e5470773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ---- Cell 5: summarize figures into short bullets (optional) ----\n",
    "# import json\n",
    "# from pathlib import Path\n",
    "\n",
    "# FIG_SYSTEM = (\"You are analyzing personal analytics plots. \"\n",
    "#               \"Infer any behavioral/trait hints the figures suggest. \"\n",
    "#               \"Return STRICT JSON per schema. Keep bullets short and avoid overclaiming.\")\n",
    "\n",
    "# FIG_SCHEMA = {\n",
    "#   \"type\":\"object\",\n",
    "#   \"properties\":{\"figure_notes\":{\"type\":\"array\",\"items\":{\"type\":\"string\"}}},\n",
    "#   \"required\":[\"figure_notes\"]\n",
    "# }\n",
    "\n",
    "# # Use the helpers you already defined earlier:\n",
    "# # - encode_image_b64(path)\n",
    "# # - chat_json_vision(system, text_prompt, images_b64, model=\"gpt-4o-mini\", max_tokens=800)\n",
    "\n",
    "# figure_paths = sorted(FIGS.glob(\"*.png\"))\n",
    "# figure_notes_all = []\n",
    "\n",
    "# if figure_paths:\n",
    "#     batches = [figure_paths[i:i+6] for i in range(0, len(figure_paths), 6)]\n",
    "#     for i, batch in enumerate(batches, 1):\n",
    "#         imgs = [encode_image_b64(p) for p in batch]\n",
    "#         text_prompt = (\n",
    "#           \"These images come from my personal analytics. \"\n",
    "#           \"Extract concise bullets describing any stable behaviors or traits implied. \"\n",
    "#           \"If unclear, return an empty list.\\nSchema:\\n\" + json.dumps(FIG_SCHEMA)\n",
    "#         )\n",
    "#         raw = chat_json_vision(FIG_SYSTEM, text_prompt, imgs, model=\"gpt-4o-mini\", max_tokens=800)\n",
    "#         js = parse_json_maybe(raw)\n",
    "#         figure_notes_all.extend(js.get(\"figure_notes\", []))\n",
    "#         print(f\"Processed figure batch {i}/{len(batches)}\")\n",
    "# else:\n",
    "#     print(\"No figures found; skipping figure summary.\")\n",
    "\n",
    "# fig_notes_path = REPORTS/\"06_persona_figure_notes.json\"\n",
    "# with open(fig_notes_path, \"w\") as f:\n",
    "#     json.dump({\"figure_notes\": figure_notes_all}, f, indent=2)\n",
    "# print(\"Saved figure notes ->\", fig_notes_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05813b03-07e8-47b5-9c8b-c003d2da42d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed figure batch 1/14 (04_pdp_ice_Ridge_sleep_duration_h.png, 04_pdp_ice_Ridge_studied_at_home.png, 04_pdp_ice_Ridge_water_drank_l.png)\n",
      "Processed figure batch 2/14 (04_pred_vs_true_test_Ridge.png, GBR(depth3)_pred_vs_true.png, LinearRegression_pred_vs_true.png)\n",
      "Processed figure batch 3/14 (RandomForest(d6)_pred_vs_true.png, Ridge(alpha=1.0)_pred_vs_true.png, Ridge(alpha=1.0)_residuals_vs_pred.png)\n",
      "Processed figure batch 4/14 (04_group_ablation_Ridge.png, 04_perm_importance_test_Ridge.png, 04_shap_beeswarm_Ridge.png)\n",
      "Processed figure batch 5/14 (04_shap_waterfall_Ridge_last_test.png, 05_trait_match_bars_hybrid.png, 05_trait_match_contrib_hybrid.png)\n",
      "Processed figure batch 6/14 (Ridge(alpha=1.0)_coefficients.png, cte_readme_overview.png, deep_sleep_pct_vs_prod.png)\n",
      "Processed figure batch 7/14 (family_no_interaction_rate.png, family_score_mean.png, friends_no_interaction_rate.png)\n",
      "Processed figure batch 8/14 (friends_score_mean.png, partner_no_interaction_rate.png, partner_score_mean.png)\n",
      "Processed figure batch 9/14 (primary_mood_distribution.png, prod_by_breakfast_quality_ci.png, prod_by_dinner_quality_ci.png)\n",
      "Processed figure batch 10/14 (prod_by_lunch_quality_ci.png, prod_by_primary_mood_box.png, prod_by_study_location.png)\n",
      "Processed figure batch 11/14 (prod_by_weekday.png, prod_over_time.png, prod_over_time_features.png)\n",
      "Processed figure batch 12/14 (prod_vs_num_prod_slots.png, reflections_top_keywords.png, reflections_wordcloud_classic.png)\n",
      "Processed figure batch 13/14 (rem_sleep_pct_vs_prod.png, secondary_mood_distribution.png, sleep_duration_vs_productivity.png)\n",
      "Processed figure batch 14/14 (when_most_productive_distribution.png)\n",
      "Saved figure notes -> /Users/deo/UMKC_phd/project_related/job_related/cte-project/notebooks/reports/06_persona_figure_notes.json\n"
     ]
    }
   ],
   "source": [
    "# ---- Cell 5 (robust): summarize figures into short bullets with retry+cache ----\n",
    "import json, time, hashlib\n",
    "from pathlib import Path\n",
    "\n",
    "FIG_SYSTEM = (\n",
    "    \"You are analyzing personal analytics plots. \"\n",
    "    \"Infer any behavioral/trait hints the figures suggest. Keep bullets short, factual, and avoid overclaiming. \"\n",
    "    \"Return STRICT JSON per schema. 0–5 bullets max.\"\n",
    ")\n",
    "\n",
    "FIG_SCHEMA = {\n",
    "  \"type\":\"object\",\n",
    "  \"properties\":{\"figure_notes\":{\"type\":\"array\",\"items\":{\"type\":\"string\"}}},\n",
    "  \"required\":[\"figure_notes\"]\n",
    "}\n",
    "\n",
    "# helpers from earlier:\n",
    "# - encode_image_b64(path)\n",
    "# - chat_json_vision(system, text_prompt, images_b64, model=\"gpt-4o-mini\", max_tokens=...)\n",
    "cache_dir = REPORTS / \"cache_fig_notes\"\n",
    "cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def cache_key(paths):\n",
    "    # cache key uses file names + sizes + mtimes — stable and cheap\n",
    "    h = hashlib.sha1()\n",
    "    for p in paths:\n",
    "        p = Path(p)\n",
    "        st = p.stat()\n",
    "        h.update(str(p.name).encode())\n",
    "        h.update(str(st.st_size).encode())\n",
    "        h.update(str(int(st.st_mtime)).encode())\n",
    "    return h.hexdigest()\n",
    "\n",
    "def get_notes_for_batch(paths, max_retries=6):\n",
    "    key = cache_key(paths)\n",
    "    cache_path = cache_dir / f\"{key}.json\"\n",
    "    if cache_path.exists():\n",
    "        try:\n",
    "            return json.loads(cache_path.read_text()).get(\"figure_notes\", [])\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    imgs = [encode_image_b64(p) for p in paths]\n",
    "    text_prompt = (\n",
    "      \"These images come from my personal analytics. \"\n",
    "      \"Extract at most 5 concise bullets describing stable behaviors/traits implied. \"\n",
    "      \"If unclear, return an empty list.\\nSchema:\\n\" + json.dumps(FIG_SCHEMA)\n",
    "    )\n",
    "\n",
    "    # polite throttle on first try\n",
    "    time.sleep(1.5)\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            raw = chat_json_vision(\n",
    "                FIG_SYSTEM, text_prompt, imgs,\n",
    "                model=\"gpt-4o-mini\", max_tokens=300  # keep small to avoid TPM spikes\n",
    "            )\n",
    "            js = parse_json_maybe(raw)\n",
    "            notes = js.get(\"figure_notes\", [])\n",
    "            cache_path.write_text(json.dumps({\"figure_notes\": notes}, indent=2))\n",
    "            return notes\n",
    "        except Exception as e:\n",
    "            # exponential backoff\n",
    "            wait = 1.5 * (2 ** attempt)\n",
    "            print(f\"Vision call throttled (attempt {attempt+1}/{max_retries}); sleeping {wait:.1f}s …\")\n",
    "            time.sleep(wait)\n",
    "    # Last resort: empty\n",
    "    return []\n",
    "\n",
    "# Pick a subset of figures first (optional): prefer the most interpretable ones\n",
    "all_figs = sorted(FIGS.glob(\"*.png\"))\n",
    "# Heuristic: prioritize model quality plots and PDP/ICE; adjust patterns as you like\n",
    "priority = [p for p in all_figs if any(tag in p.name.lower() for tag in [\"leader\", \"pdp_ice\", \"pred\", \"residual\", \"feature_importance\"])]\n",
    "others   = [p for p in all_figs if p not in priority]\n",
    "figure_paths = priority + others\n",
    "\n",
    "# Smaller batches to reduce per-request payload\n",
    "batch_size = 3\n",
    "batches = [figure_paths[i:i+batch_size] for i in range(0, len(figure_paths), batch_size)]\n",
    "\n",
    "figure_notes_all = []\n",
    "if figure_paths:\n",
    "    for i, batch in enumerate(batches, 1):\n",
    "        notes = get_notes_for_batch(batch)\n",
    "        figure_notes_all.extend(notes)\n",
    "        names = \", \".join([p.name for p in batch])\n",
    "        print(f\"Processed figure batch {i}/{len(batches)} ({names})\")\n",
    "else:\n",
    "    print(\"No figures found; skipping figure summary.\")\n",
    "\n",
    "fig_notes_path = REPORTS/\"06_persona_figure_notes.json\"\n",
    "with open(fig_notes_path, \"w\") as f:\n",
    "    json.dump({\"figure_notes\": figure_notes_all}, f, indent=2)\n",
    "print(\"Saved figure notes ->\", fig_notes_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aadc145-f490-4e63-ba82-e50ac25c6537",
   "metadata": {},
   "source": [
    "## 6) Reduce: combine maps (+ KPIs + optional figures) → final persona JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccce563d-17e1-44b2-8a0e-01cf17a52aa1",
   "metadata": {},
   "source": [
    "This aggregates trait scores, adds KPIs, pulls in any hybrid summary you may have, and produces your one-time persona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fba4441f-5da8-4087-9b4c-00d9b665b07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved persona profile -> /Users/deo/UMKC_phd/project_related/job_related/cte-project/notebooks/reports/06_profile_persona_llm.json\n"
     ]
    }
   ],
   "source": [
    "# ---- Cell 6: reduce to a single persona JSON ----\n",
    "import json, numpy as np, pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load map outputs\n",
    "maps_path = REPORTS/\"06_persona_maps.json\"\n",
    "with open(maps_path) as f:\n",
    "    map_outputs = json.load(f)\n",
    "\n",
    "# Load optional figure bullets\n",
    "fig_notes = []\n",
    "fig_notes_path = REPORTS/\"06_persona_figure_notes.json\"\n",
    "if fig_notes_path.exists():\n",
    "    with open(fig_notes_path) as f:\n",
    "        fig_notes = json.load(f).get(\"figure_notes\", [])\n",
    "\n",
    "# Optional: hybrid trait CSV you may have created earlier\n",
    "hybrid_path = REPORTS/\"05_profile_traits_hybrid.csv\"\n",
    "hybrid_traits = {}\n",
    "if hybrid_path.exists():\n",
    "    try:\n",
    "        hybrid_traits = pd.read_csv(hybrid_path, index_col=0).squeeze(\"columns\").to_dict()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# KPIs from earlier cells (if you built `kpi`), else make a light version now:\n",
    "kpi = dict(kpi) if \"kpi\" in globals() else {}\n",
    "if not kpi:\n",
    "    kpi = {\n",
    "        \"days\": int(len(df)),\n",
    "        \"reflections_with_text\": int(df[\"reflection\"].astype(str).str.strip().str.len().gt(0).sum()) if \"reflection\" in df else 0,\n",
    "        \"avg_sleep_h\": float(df.get(\"sleep_duration_h\", pd.Series([np.nan]*len(df))).mean()),\n",
    "        \"sleep_std_h\": float(df.get(\"sleep_duration_h\", pd.Series([np.nan]*len(df))).std() or 0.0),\n",
    "        \"avg_productivity_pct\": float(df.get(\"productivity_pct\", pd.Series([np.nan]*len(df))).mean()),\n",
    "    }\n",
    "\n",
    "# Aggregate traits across map chunks (median score, mean confidence)\n",
    "TRAITS = [\n",
    "  \"focus\",\"reliability\",\"initiative\",\"communication\",\"adaptability\",\n",
    "  \"curiosity\",\"impact\",\"teamwork\",\"independence\",\"planning\",\n",
    "  \"resilience\",\"learning_mindset\"\n",
    "]\n",
    "\n",
    "scores = defaultdict(list)\n",
    "confs  = defaultdict(list)\n",
    "\n",
    "for js in map_outputs:\n",
    "    per = js.get(\"per_trait\", {})\n",
    "    for t, d in per.items():\n",
    "        s = d.get(\"score\", None)\n",
    "        c = d.get(\"confidence\", None)\n",
    "        if s is not None:\n",
    "            scores[t].append(float(s))\n",
    "        if c is not None:\n",
    "            confs[t].append(float(c))\n",
    "\n",
    "agg = {}\n",
    "for t in TRAITS:\n",
    "    sc = scores.get(t, [])\n",
    "    cf = confs.get(t, [])\n",
    "    agg[t] = {\n",
    "        \"score_median\": float(np.median(sc)) if sc else 0.0,\n",
    "        \"confidence_mean\": float(np.mean(cf)) if cf else 0.0,\n",
    "        \"n_chunks\": len(sc),\n",
    "    }\n",
    "\n",
    "# Pick a few evidence quotes from reflections (pos/neg days)\n",
    "from textblob import TextBlob\n",
    "def _clean_text(s):\n",
    "    s = str(s or \"\").replace(\"\\n\",\" \").strip()\n",
    "    return re.sub(r\"\\s+\",\" \", s)\n",
    "\n",
    "if \"reflection\" in df.columns:\n",
    "    refl = df[\"reflection\"].astype(str).apply(_clean_text)\n",
    "    # reuse sentiment computed earlier if present; else compute lightweight polarity\n",
    "    if \"refl_sent_compound\" in df:\n",
    "        pos = df.sort_values(\"refl_sent_compound\", ascending=False).head(3)\n",
    "        neg = df.sort_values(\"refl_sent_compound\", ascending=True ).head(2)\n",
    "    else:\n",
    "        pol = refl.apply(lambda t: TextBlob(t).sentiment.polarity)\n",
    "        tmp = df.copy()\n",
    "        tmp[\"pol\"] = pol\n",
    "        pos = tmp.sort_values(\"pol\", ascending=False).head(3)\n",
    "        neg = tmp.sort_values(\"pol\", ascending=True ).head(2)\n",
    "    evidence_quotes = []\n",
    "    for _,row in pos.iterrows():\n",
    "        t = _clean_text(row.get(\"reflection\",\"\"))\n",
    "        if t: evidence_quotes.append(f\"POS[{str(row.get('date',''))[:10]}] {t[:160]}\")\n",
    "    for _,row in neg.iterrows():\n",
    "        t = _clean_text(row.get(\"reflection\",\"\"))\n",
    "        if t: evidence_quotes.append(f\"CHALLENGE[{str(row.get('date',''))[:10]}] {t[:160]}\")\n",
    "else:\n",
    "    evidence_quotes = []\n",
    "\n",
    "# LLM reduce prompt (JSON mode)\n",
    "PERSONA_SCHEMA = {\n",
    "  \"type\":\"object\",\n",
    "  \"properties\":{\n",
    "    \"per_trait\": {\n",
    "      \"type\":\"object\",\n",
    "      \"additionalProperties\":{\n",
    "        \"type\":\"object\",\n",
    "        \"properties\":{\n",
    "          \"score\":{\"type\":\"number\"},\n",
    "          \"confidence\":{\"type\":\"number\"},\n",
    "          \"note\":{\"type\":\"string\"}\n",
    "        },\n",
    "        \"required\":[\"score\",\"confidence\"]\n",
    "      }\n",
    "    },\n",
    "    \"summary\":{\"type\":\"string\"},\n",
    "    \"title\":{\"type\":\"string\"},\n",
    "    \"strengths\":{\"type\":\"array\",\"items\":{\"type\":\"string\"}},\n",
    "    \"growth_areas\":{\"type\":\"array\",\"items\":{\"type\":\"string\"}},\n",
    "    \"evidence_quotes\":{\"type\":\"array\",\"items\":{\"type\":\"string\"}},\n",
    "    \"persona_version\":{\"type\":\"string\"}\n",
    "  },\n",
    "  \"required\":[\"per_trait\",\"summary\",\"strengths\",\"growth_areas\"]\n",
    "}\n",
    "\n",
    "REDUCE_SYSTEM = (\n",
    " \"You create a reusable behavioral persona based on aggregates/KPIs/evidence. \"\n",
    " \"Return STRICT JSON matching the schema; concise and job-relevant.\"\n",
    ")\n",
    "\n",
    "reduce_text = (\n",
    "    \"Aggregate per-trait stats, KPIs, optional numeric hybrid traits, figure-derived notes, and short evidence quotes follow.\\n\"\n",
    "    \"Produce a persona JSON per the schema below.\\n\\n\"\n",
    "    f\"TRAIT AGGREGATES:\\n{json.dumps(agg, indent=2)}\\n\\n\"\n",
    "    f\"KPIs:\\n{json.dumps(kpi, indent=2)}\\n\\n\"\n",
    "    f\"HYBRID TRAITS (optional):\\n{json.dumps(hybrid_traits, indent=2)}\\n\\n\"\n",
    "    f\"FIGURE NOTES (optional):\\n{json.dumps(fig_notes[:12], indent=2)}\\n\\n\"\n",
    "    f\"EVIDENCE QUOTES:\\n{json.dumps(evidence_quotes[:5], indent=2)}\\n\\n\"\n",
    "    f\"SCHEMA:\\n{json.dumps(PERSONA_SCHEMA, indent=2)}\"\n",
    ")\n",
    "\n",
    "persona_raw = chat_json(REDUCE_SYSTEM, reduce_text, model=\"gpt-4.1-mini\", max_tokens=1400)\n",
    "persona = parse_json_maybe(persona_raw)\n",
    "\n",
    "# Stamp and save\n",
    "if \"persona_version\" not in persona:\n",
    "    persona[\"persona_version\"] = \"v1-\" + pd.Timestamp.utcnow().strftime(\"%Y%m%dT%H%MZ\")\n",
    "persona_path = REPORTS/\"06_profile_persona_llm.json\"\n",
    "with open(persona_path, \"w\") as f:\n",
    "    json.dump(persona, f, indent=2)\n",
    "print(\"Saved persona profile ->\", persona_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfed888-a5f4-4482-b52f-fc12d8d137f3",
   "metadata": {},
   "source": [
    "## 7) Quick peek (sanity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72f3aaba-8609-4cae-a170-dc4283d5768f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITLE: Moderately Focused Independent Performer with Strong Resilience\n",
      "SUMMARY: This persona demonstrates moderate focus, reliability, and planning with strong independence, resilience, and initiative. Communication, curiosity, teamwork, and impact are areas with lower scores, indicating a preference for autonomous work and potential challenges in collaboration and exploration. Sleep and productivity patterns suggest the importance of rest and consistent study habits for optimal performance.\n",
      "\n",
      "Top strengths: ['Independence in work', 'Resilience to setbacks', 'Proactive initiative', 'Learning mindset openness']\n",
      "Growth areas: ['Enhancing communication and collaboration skills', 'Increasing curiosity and exploratory learning', 'Improving teamwork engagement', 'Boosting overall impact and influence']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>confidence</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>independence</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>High independence; comfortable working autonom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resilience</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>High resilience; able to recover from setbacks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>initiative</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>Above average initiative; tends to take action...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_mindset</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>Above average learning mindset; open to growth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaptability</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>Moderate adaptability; able to adjust to chang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>focus</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>Moderate focus with high confidence; some vari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reliability</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>Moderate reliability; consistent but with room...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>planning</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>Moderate planning skills; some structure but i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  score  confidence  \\\n",
       "independence       0.65      0.8750   \n",
       "resilience         0.65      0.9000   \n",
       "initiative         0.60      0.8625   \n",
       "learning_mindset   0.60      0.8750   \n",
       "adaptability       0.55      0.8750   \n",
       "focus              0.45      0.9000   \n",
       "reliability        0.45      0.8750   \n",
       "planning           0.45      0.8750   \n",
       "\n",
       "                                                               note  \n",
       "independence      High independence; comfortable working autonom...  \n",
       "resilience        High resilience; able to recover from setbacks...  \n",
       "initiative        Above average initiative; tends to take action...  \n",
       "learning_mindset  Above average learning mindset; open to growth...  \n",
       "adaptability      Moderate adaptability; able to adjust to chang...  \n",
       "focus             Moderate focus with high confidence; some vari...  \n",
       "reliability       Moderate reliability; consistent but with room...  \n",
       "planning          Moderate planning skills; some structure but i...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---- Cell 7: quick peek ----\n",
    "import json, pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "with open(REPORTS/\"06_profile_persona_llm.json\") as f:\n",
    "    persona = json.load(f)\n",
    "\n",
    "print(\"TITLE:\", persona.get(\"title\"))\n",
    "print(\"SUMMARY:\", persona.get(\"summary\"))\n",
    "print(\"\\nTop strengths:\", persona.get(\"strengths\"))\n",
    "print(\"Growth areas:\", persona.get(\"growth_areas\"))\n",
    "\n",
    "pt = pd.DataFrame.from_dict(persona.get(\"per_trait\", {}), orient=\"index\")\n",
    "if not pt.empty:\n",
    "    pt = pt[[\"score\",\"confidence\",\"note\"]].sort_values(\"score\", ascending=False)\n",
    "    display(pt.head(8))\n",
    "else:\n",
    "    print(\"No per_trait data found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32d1143-f839-4c75-8f38-4400957e7b9b",
   "metadata": {},
   "source": [
    "## 8) Validate persona shape & export a mini card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba405fec-e1a5-4be1-adf6-2752a78e5a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote mini card -> /Users/deo/UMKC_phd/project_related/job_related/cte-project/notebooks/reports/06_persona_card.md\n"
     ]
    }
   ],
   "source": [
    "# ---- Cell 8: validate & export a mini Markdown card ----\n",
    "import json, pandas as pd\n",
    "\n",
    "req = [\"per_trait\",\"summary\",\"strengths\",\"growth_areas\"]\n",
    "missing = [k for k in req if k not in persona]\n",
    "assert not missing, f\"Persona missing keys: {missing}\"\n",
    "\n",
    "md = f\"\"\"### Persona: {persona.get('title','')}\n",
    "{persona.get('summary','')}\n",
    "\n",
    "**Top strengths:** {\", \".join(persona.get('strengths', [])[:5])}  \n",
    "**Growth areas:** {\", \".join(persona.get('growth_areas', [])[:3])}\n",
    "\"\"\"\n",
    "card_path = REPORTS / \"06_persona_card.md\"\n",
    "card_path.write_text(md)\n",
    "print(\"Wrote mini card ->\", card_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a33c66-18e1-4058-90c1-97f3a64a56d7",
   "metadata": {},
   "source": [
    "# Part 2 — Per-JD (Job Description) Fit Verdict\n",
    "\n",
    "Now that we have 06_profile_persona_llm.json, this is the tiny JD-fit pipeline.\n",
    "\n",
    "## 9) Paste a JD here (raw text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4d108ad-41ae-494f-92a4-21d707c7b26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JD length: 2051\n"
     ]
    }
   ],
   "source": [
    "# ---- Cell 9: paste a JD to evaluate ----\n",
    "# for example below I have pasted JD for DS 2 role at Garmin posted on LinkedIN\n",
    "jd_text = \"\"\"\n",
    "Data Scientist [$100-$120/hr]\n",
    "\n",
    "AI Task Evaluation & Statistical Analysis Specialist\n",
    "\n",
    "\n",
    "\n",
    "As an independent member of the referral program of a leading organization, we are posting to seek a data-driven analyst to conduct comprehensive failure analysis on AI agent performance across finance-sector tasks. You'll identify patterns, root causes, and systemic issues in our evaluation framework by analyzing task performance across multiple dimensions (task types, file types, criteria, etc.).\n",
    "\n",
    "\n",
    "Key Responsibilities\n",
    "Statistical Failure Analysis: Identify patterns in AI agent failures across task components (prompts, rubrics, templates, file types, tags)\n",
    "Root Cause Analysis: Determine whether failures stem from task design, rubric clarity, file complexity, or agent limitations\n",
    "Dimension Analysis: Analyze performance variations across finance sub-domains, file types, and task categories\n",
    "Reporting & Visualization: Create dashboards and reports highlighting failure clusters, edge cases, and improvement opportunities\n",
    "Quality Framework: Recommend improvements to task design, rubric structure, and evaluation criteria based on statistical findings\n",
    "Stakeholder Communication: Present insights to data labeling experts and technical teams\n",
    "\n",
    "\n",
    "Required Qualifications\n",
    "Statistical Expertise: Strong foundation in statistical analysis, hypothesis testing, and pattern recognition\n",
    "Programming: Proficiency in Python (pandas, scipy, matplotlib/seaborn) or R for data analysis\n",
    "Data Analysis: Experience with exploratory data analysis and creating actionable insights from complex datasets\n",
    "AI/ML Familiarity: Understanding of LLM evaluation methods and quality metrics\n",
    "Tools: Comfortable working with Excel, data visualization tools (Tableau/Looker), andSQL\n",
    "\n",
    "\n",
    "Preferred Qualifications\n",
    "Experience with AI/ML model evaluation or quality assurance\n",
    "Background in finance or willingness to learn finance domain concepts\n",
    "Experience with multi-dimensional failure analysis\n",
    "Familiarity with benchmark datasets and evaluation frameworks\n",
    "2-4 years of relevant experience\n",
    "\"\"\"\n",
    "print(\"JD length:\", len(jd_text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7502b721-b2d4-4978-871b-412db4862256",
   "metadata": {},
   "source": [
    "## 10) CTE strict verdict (LLM only picks required traits; scoring is deterministic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "023d9b3d-f873-40c4-a0fc-184207783465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================\n",
      "CTE Character-Fit Verdict for Deo  |  Window: 72 days (2025-01-27 → 2025-04-30)\n",
      "========================================================================\n",
      "Verdict: Likely to struggle ⚠️\n",
      "Overall: Not a fit   |   Match score: 0.29   |   Hiring risk: high-risk\n",
      "\n",
      "Required traits & match:\n",
      "trait\trequired_level\tcandidate_score\tmet\n",
      "focus\thigh\t0.45\tFalse\n",
      "communication\thigh\t0.3\tFalse\n",
      "independence\thigh\t0.65\tTrue\n",
      "curiosity\tmedium\t0.2\tFalse\n",
      "learning_mindset\tmedium\t0.6\tTrue\n",
      "planning\tmedium\t0.45\tFalse\n",
      "impact\tmedium\t0.35\tFalse\n",
      "\n",
      "Why this outcome (character-only):\n",
      "Strengths:\n",
      " • independence (score 0.65 ≥ 0.50)\n",
      " • learning_mindset (score 0.6 ≥ 0.50)\n",
      "\n",
      "Risks (if hired):\n",
      " • focus (score 0.45 < 0.50)\n",
      " • communication (score 0.3 < 0.50)\n",
      " • curiosity (score 0.2 < 0.50)\n",
      " • planning (score 0.45 < 0.50)\n",
      " • impact (score 0.35 < 0.50)\n",
      "\n",
      "Saved -> /Users/deo/UMKC_phd/project_related/job_related/cte-project/notebooks/reports/06_final_verdict_20251109_153544.json\n"
     ]
    }
   ],
   "source": [
    "# ---- Cell 10: Strict CTE verdict (LLM extracts JD traits; scoring is deterministic) ----\n",
    "import json, pandas as pd, datetime, itertools\n",
    "\n",
    "CANDIDATE_NAME = \"Deo\"\n",
    "\n",
    "# 0) Load persona we synthesized earlier\n",
    "with open(REPORTS/\"06_profile_persona_llm.json\") as f:\n",
    "    persona = json.load(f)\n",
    "per_trait = persona.get(\"per_trait\", {})\n",
    "\n",
    "# 1) LLM: extract required behavioral traits (low|medium|high)\n",
    "REQUIRED_SYSTEM = (\n",
    " \"You analyze a job description and extract the *behavioral* traits needed to thrive in the role. \"\n",
    " \"Focus on traits like: focus, reliability, initiative, communication, teamwork, adaptability, \"\n",
    " \"curiosity, impact, independence, planning, resilience, learning_mindset. \"\n",
    " \"Return STRICT JSON {requirements: [{trait, required_level}]}, where required_level ∈ {low, medium, high}. \"\n",
    " \"Limit to 5–8 traits.\"\n",
    ")\n",
    "REQUIRED_SCHEMA = {\n",
    "  \"type\":\"object\",\n",
    "  \"properties\":{\n",
    "    \"requirements\":{\"type\":\"array\",\"items\":{\n",
    "      \"type\":\"object\",\n",
    "      \"properties\":{\"trait\":{\"type\":\"string\"},\"required_level\":{\"type\":\"string\"}},\n",
    "      \"required\":[\"trait\",\"required_level\"]\n",
    "    }}\n",
    "  },\n",
    "  \"required\":[\"requirements\"]\n",
    "}\n",
    "req_prompt = \"JOB DESCRIPTION:\\n\" + jd_text + \"\\n\\nSchema:\\n\" + json.dumps(REQUIRED_SCHEMA)\n",
    "req_raw  = chat_json(REQUIRED_SYSTEM, req_prompt, model=\"gpt-4.1-mini\", max_tokens=500)\n",
    "req_json = parse_json_maybe(req_raw)\n",
    "requirements = req_json.get(\"requirements\", [])\n",
    "\n",
    "# 2) Scoring policy (edit here to change rules)\n",
    "LEVEL_THRESH = {\"low\": 0.50, \"medium\": 0.50, \"high\": 0.50}   # recommended cutoffs\n",
    "LEVEL_WEIGHT = {\"low\": 1.0, \"medium\": 1.1, \"high\": 1.2}      # high counts more\n",
    "\n",
    "rows, total_w, met_w = [], 0.0, 0.0\n",
    "for r in requirements:\n",
    "    t = r.get(\"trait\",\"\").strip()\n",
    "    lvl = r.get(\"required_level\",\"low\").lower()\n",
    "    if not (t and lvl in LEVEL_THRESH and t in per_trait): \n",
    "        continue\n",
    "    score = float(per_trait[t].get(\"score\", 0.0))\n",
    "    thr   = LEVEL_THRESH[lvl]; w = LEVEL_WEIGHT[lvl]\n",
    "    met   = score >= thr\n",
    "    rows.append({\"trait\":t, \"required_level\":lvl, \"candidate_score\":round(score,2), \"threshold\":thr, \"met\":met})\n",
    "    total_w += w; \n",
    "    if met: met_w += w\n",
    "\n",
    "if total_w == 0: total_w = 1.0\n",
    "match_ratio = met_w / total_w\n",
    "\n",
    "if   match_ratio >= 0.75: overall, risk = \"Strong fit\", \"low-risk\"\n",
    "elif match_ratio >= 0.50: overall, risk = \"Possible fit\", \"moderate-risk\"\n",
    "elif match_ratio >= 0.35: overall, risk = \"Leaning no\", \"elevated-risk\"\n",
    "else:                     overall, risk = \"Not a fit\",  \"high-risk\"\n",
    "\n",
    "# 3) Observation window (robust; fixes the 1970-01-01 issue)\n",
    "def infer_span_from_df(df_like):\n",
    "    if df_like is None or not hasattr(df_like, \"columns\"): return None\n",
    "    # Prefer date-like columns\n",
    "    for c in df_like.columns:\n",
    "        if \"date\" in str(c).lower() or \"time\" in str(c).lower():\n",
    "            s = pd.to_datetime(df_like[c], errors=\"coerce\").dropna()\n",
    "            if not s.empty:\n",
    "                return {\"n_days\": int(s.dt.date.nunique()), \"dmin\": s.min().date(), \"dmax\": s.max().date()}\n",
    "    # Fallback: try every column to find any parseable datetime\n",
    "    for c in df_like.columns:\n",
    "        s = pd.to_datetime(df_like[c], errors=\"coerce\").dropna()\n",
    "        if not s.empty:\n",
    "            return {\"n_days\": int(s.dt.date.nunique()), \"dmin\": s.min().date(), \"dmax\": s.max().date()}\n",
    "    return None\n",
    "\n",
    "_span = None\n",
    "try:\n",
    "    # prefer your cleaned files\n",
    "    p1 = DATA / \"clean.parquet\"; p2 = DATA / \"interim\" / \"features.parquet\"\n",
    "    if p1.exists(): _span = infer_span_from_df(pd.read_parquet(p1))\n",
    "    elif p2.exists(): _span = infer_span_from_df(pd.read_parquet(p2))\n",
    "except Exception:\n",
    "    _span = None\n",
    "\n",
    "if _span is None and 'chunks' in globals():  # from your reflection mapping step\n",
    "    try:\n",
    "        all_lines = list(itertools.chain.from_iterable(chunks))\n",
    "        dates = [ln.split(\" :: \", 1)[0] for ln in all_lines if \" :: \" in ln]\n",
    "        s = pd.to_datetime(dates, errors=\"coerce\").dropna()\n",
    "        if not s.empty:\n",
    "            _span = {\"n_days\": int(s.dt.date.nunique()), \"dmin\": s.min().date(), \"dmax\": s.max().date()}\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "span_str = f\"{_span['n_days']} days ({_span['dmin']} → {_span['dmax']})\" if _span else \"72 days (Jan–Apr 2025)\"\n",
    "\n",
    "# 4) Pretty, GUI-friendly print (positive-first option is in Cell 12)\n",
    "def md_list(items): \n",
    "    return \"\\n\".join([f\" • {it}\" for it in items]) if items else \" • —\"\n",
    "\n",
    "strengths = [f\"{r['trait']} (score {r['candidate_score']} ≥ {LEVEL_THRESH[r['required_level']]:.2f})\"\n",
    "             for r in rows if r[\"met\"]]\n",
    "gaps = [f\"{r['trait']} (score {r['candidate_score']} < {LEVEL_THRESH[r['required_level']]:.2f})\"\n",
    "        for r in rows if not r[\"met\"]]\n",
    "\n",
    "print(\"\\n\" + \"=\"*72)\n",
    "print(f\"CTE Character-Fit Verdict for {CANDIDATE_NAME}  |  Window: {span_str}\")\n",
    "print(\"=\"*72)\n",
    "print(f\"Verdict: {'Likely successful ✅' if match_ratio>=0.50 else 'Likely to struggle ⚠️'}\")\n",
    "print(f\"Overall: {overall}   |   Match score: {match_ratio:.2f}   |   Hiring risk: {risk}\\n\")\n",
    "\n",
    "print(\"Required traits & match:\")\n",
    "if rows:\n",
    "    print(\"trait\\trequired_level\\tcandidate_score\\tmet\")\n",
    "    for r in rows:\n",
    "        print(f\"{r['trait']}\\t{r['required_level']}\\t{r['candidate_score']}\\t{r['met']}\")\n",
    "else:\n",
    "    print(\"(no traits extracted from JD)\")\n",
    "\n",
    "print(\"\\nWhy this outcome (character-only):\")\n",
    "print(\"Strengths:\\n\" + md_list(strengths))\n",
    "print(\"\\nRisks (if hired):\\n\" + md_list(gaps))\n",
    "\n",
    "# 5) Save compact JSON for the GUI & API\n",
    "final = {\n",
    "    \"candidate\": CANDIDATE_NAME,\n",
    "    \"observation_window\": span_str,\n",
    "    \"overall\": overall,\n",
    "    \"verdict\": \"Likely successful\" if match_ratio>=0.50 else \"Likely to struggle\",\n",
    "    \"match_score\": round(match_ratio, 2),\n",
    "    \"risk_band\": risk,\n",
    "    \"requirements\": rows,\n",
    "    \"strengths\": strengths,\n",
    "    \"gaps\": gaps,\n",
    "    \"generated_at\": datetime.datetime.now().isoformat(timespec=\"seconds\")\n",
    "}\n",
    "ts = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "json_path = REPORTS / f\"06_final_verdict_{ts}.json\"\n",
    "with open(json_path, \"w\") as f: json.dump(final, f, indent=2)\n",
    "print(f\"\\nSaved -> {json_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0403c4cc-1227-48a2-b4b7-e6a583f06d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid JD requirements:\n",
      "[\n",
      "  {\n",
      "    \"trait\": \"independence\",\n",
      "    \"required_level\": \"medium\"\n",
      "  },\n",
      "  {\n",
      "    \"trait\": \"communication\",\n",
      "    \"required_level\": \"medium\"\n",
      "  },\n",
      "  {\n",
      "    \"trait\": \"curiosity\",\n",
      "    \"required_level\": \"medium\"\n",
      "  },\n",
      "  {\n",
      "    \"trait\": \"learning_mindset\",\n",
      "    \"required_level\": \"medium\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Trace (first 3 JD lines per trait):\n",
      "[\n",
      "  {\n",
      "    \"trait\": \"independence\",\n",
      "    \"required_level\": \"medium\",\n",
      "    \"snippets\": [\n",
      "      \"As an independent member of the referral program of a leading organization, we are posting to seek a data-driven analyst to conduct comprehensive failure analysis on AI agent performance across finance-sector tasks. You'll identify patterns, root causes, and systemic issues in our evaluation framework by analyzing task performance across multiple dimensions (task types, file types, criteria, etc.).\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"trait\": \"communication\",\n",
      "    \"required_level\": \"medium\",\n",
      "    \"snippets\": [\n",
      "      \"Stakeholder Communication: Present insights to data labeling experts and technical teams\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"trait\": \"curiosity\",\n",
      "    \"required_level\": \"medium\",\n",
      "    \"snippets\": [\n",
      "      \"Data Analysis: Experience with exploratory data analysis and creating actionable insights from complex datasets\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"trait\": \"learning_mindset\",\n",
      "    \"required_level\": \"medium\",\n",
      "    \"snippets\": [\n",
      "      \"Background in finance or willingness to learn finance domain concepts\"\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# ---- Cell 11: Hybrid JD→Traits (traceable) ----\n",
    "import re, json\n",
    "from collections import defaultdict\n",
    "\n",
    "# 1) Small synonym lexicon: map JD phrases → behavioral traits\n",
    "LEXICON = {\n",
    "    \"communication\":  [r\"\\b(stakeholder|present|communicat(e|ion)|storytell|clear writing)\\b\"],\n",
    "    \"teamwork\":       [r\"\\b(cross-?functional|collaborat(e|ion)|partner|peer review|team)\\b\"],\n",
    "    \"focus\":          [r\"\\b(detail-?oriented|attention to detail|meticulous|thorough)\\b\"],\n",
    "    \"planning\":       [r\"\\b(roadmap|plan|milestone|organize|prioriti[sz]e|deadline|cadence)\\b\"],\n",
    "    \"reliability\":    [r\"\\b(reliable|consisten(t|cy)|accountab(le|ility)|ownership)\\b\"],\n",
    "    \"initiative\":     [r\"\\b(proactive|initiative|self-?starter|drive|ownership)\\b\"],\n",
    "    \"adaptability\":   [r\"\\b(adapt(|ability)|ambiguity|change|flexible|fast-?paced)\\b\"],\n",
    "    \"impact\":         [r\"\\b(impact|business value|outcome|results|influence)\\b\"],\n",
    "    \"independence\":   [r\"\\b(autonom(y|ous)|independent|self-?directed)\\b\"],\n",
    "    \"curiosity\":      [r\"\\b(curio(us|sity)|explor(e|atory)|question|dig deeper)\\b\"],\n",
    "    \"resilience\":     [r\"\\b(resilien(t|ce)|setback|grit|persist|iterate)\\b\"],\n",
    "    \"learning_mindset\":[r\"\\b(learn(ing)?|upskill|new (tools|techniques)|keep up to date)\\b\"]\n",
    "}\n",
    "\n",
    "# 2) Intensity words → required_level\n",
    "INTENSIFIERS = {\n",
    "    \"high\":   [r\"\\b(excellent|exceptional|expert|outstanding|world-?class|strong)\\b\"],\n",
    "    \"medium\": [r\"\\b(solid|proficient|good|effective|comfortable)\\b\"],\n",
    "    \"low\":    [r\"\\b(basic|familiar|some exposure)\\b\"]\n",
    "}\n",
    "\n",
    "lines = [ln.strip() for ln in jd_text.splitlines() if ln.strip()]\n",
    "hits = defaultdict(list)\n",
    "for ln in lines:\n",
    "    for trait, pats in LEXICON.items():\n",
    "        for p in pats:\n",
    "            if re.search(p, ln, flags=re.I):\n",
    "                hits[trait].append(ln)\n",
    "\n",
    "def decide_level(snips):\n",
    "    text = \" \".join(snips)[:2000]\n",
    "    score = {\"low\": 0, \"medium\": 0, \"high\": 0}\n",
    "    for lvl, pats in INTENSIFIERS.items():\n",
    "        for p in pats:\n",
    "            score[lvl] += len(re.findall(p, text, flags=re.I))\n",
    "    if score[\"high\"]>0:   return \"high\"\n",
    "    if score[\"medium\"]>0: return \"medium\"\n",
    "    if score[\"low\"]>0:    return \"low\"\n",
    "    return \"medium\"  # default if trait appears with no intensifiers\n",
    "\n",
    "requirements_hybrid = []\n",
    "trace = []\n",
    "for trait, snips in hits.items():\n",
    "    lvl = decide_level(snips)\n",
    "    requirements_hybrid.append({\"trait\": trait, \"required_level\": lvl})\n",
    "    trace.append({\"trait\": trait, \"required_level\": lvl, \"snippets\": snips[:3]})\n",
    "\n",
    "# Fallback to your LLM extraction if the lexicon finds nothing\n",
    "if not requirements_hybrid:\n",
    "    # `requirements` is the LLM-based list created in Cell 10\n",
    "    requirements_hybrid = requirements\n",
    "    trace = [{\"trait\": r[\"trait\"], \"required_level\": r[\"required_level\"], \"snippets\": []} for r in requirements_hybrid]\n",
    "\n",
    "print(\"Hybrid JD requirements:\")\n",
    "print(json.dumps(requirements_hybrid, indent=2))\n",
    "print(\"\\nTrace (first 3 JD lines per trait):\")\n",
    "print(json.dumps(trace, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e6554c28-75b3-4589-bb7c-58c7fcd05ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================\n",
      "CTE Character-Fit Verdict for Deo  |  (Hybrid JD requirements)\n",
      "========================================================================\n",
      "Verdict: Likely successful ✅\n",
      "Overall: Possible fit   |   Match score: 0.50   |   Hiring risk: moderate-risk\n",
      "\n",
      "Required traits & match:\n",
      "trait\trequired_level\tcandidate_score\tmet\n",
      "independence\tmedium\t0.65\tTrue\n",
      "communication\tmedium\t0.3\tFalse\n",
      "curiosity\tmedium\t0.2\tFalse\n",
      "learning_mindset\tmedium\t0.6\tTrue\n",
      "\n",
      "Saved -> /Users/deo/UMKC_phd/project_related/job_related/cte-project/notebooks/reports/06_final_verdict_hybrid_20251109_163603.json\n"
     ]
    }
   ],
   "source": [
    "# ---- Cell 12: Re-score (hybrid requirements) ----\n",
    "import json, datetime\n",
    "\n",
    "# Load persona again (just to be self-contained)\n",
    "with open(REPORTS/\"06_profile_persona_llm.json\") as f:\n",
    "    persona = json.load(f)\n",
    "per_trait = persona.get(\"per_trait\", {})\n",
    "\n",
    "# Use hybrid requirements if present; else fall back to Cell 10's `requirements`\n",
    "reqs = requirements_hybrid if 'requirements_hybrid' in globals() and requirements_hybrid else requirements\n",
    "\n",
    "LEVEL_THRESH = {\"low\": 0.50, \"medium\": 0.50, \"high\": 0.50}\n",
    "LEVEL_WEIGHT = {\"low\": 1.0, \"medium\": 1.1, \"high\": 1.2}\n",
    "UNMET_HIGH_PENALTY = 0.05  # gentle nudge\n",
    "\n",
    "rows, total_w, met_w = [], 0.0, 0.0\n",
    "any_unmet_high = False\n",
    "for r in reqs:\n",
    "    t = r.get(\"trait\",\"\").strip()\n",
    "    lvl = r.get(\"required_level\",\"low\").lower()\n",
    "    if not (t and lvl in LEVEL_THRESH and t in per_trait):\n",
    "        continue\n",
    "    score = float(per_trait[t].get(\"score\", 0.0))\n",
    "    thr   = LEVEL_THRESH[lvl]; w = LEVEL_WEIGHT[lvl]\n",
    "    met   = score >= thr\n",
    "    rows.append({\"trait\":t, \"required_level\":lvl, \"candidate_score\":round(score,2), \"threshold\":thr, \"met\":met})\n",
    "    total_w += w\n",
    "    if met: met_w += w\n",
    "    if (not met) and (lvl == \"high\"): any_unmet_high = True\n",
    "\n",
    "if total_w == 0: total_w = 1.0\n",
    "match_ratio = met_w / total_w\n",
    "if any_unmet_high:\n",
    "    match_ratio = max(0.0, match_ratio - UNMET_HIGH_PENALTY)\n",
    "\n",
    "if   match_ratio >= 0.75: overall, risk = \"Strong fit\", \"low-risk\"\n",
    "elif match_ratio >= 0.50: overall, risk = \"Possible fit\", \"moderate-risk\"\n",
    "elif match_ratio >= 0.35: overall, risk = \"Leaning no\", \"elevated-risk\"\n",
    "else:                      overall, risk = \"Not a fit\",  \"high-risk\"\n",
    "\n",
    "# Pretty print\n",
    "print(\"\\n\" + \"=\"*72)\n",
    "print(\"CTE Character-Fit Verdict for Deo  |  (Hybrid JD requirements)\")\n",
    "print(\"=\"*72)\n",
    "print(f\"Verdict: {'Likely successful ✅' if match_ratio>=0.50 else 'Likely to struggle ⚠️'}\")\n",
    "print(f\"Overall: {overall}   |   Match score: {match_ratio:.2f}   |   Hiring risk: {risk}\\n\")\n",
    "print(\"Required traits & match:\")\n",
    "print(\"trait\\trequired_level\\tcandidate_score\\tmet\")\n",
    "for r in rows:\n",
    "    print(f\"{r['trait']}\\t{r['required_level']}\\t{r['candidate_score']}\\t{r['met']}\")\n",
    "\n",
    "# Save compact JSON for the GUI / API\n",
    "ts = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "with open(REPORTS / f\"06_final_verdict_hybrid_{ts}.json\",\"w\") as f:\n",
    "    json.dump({\n",
    "        \"candidate\": \"Deo\",\n",
    "        \"overall\": overall,\n",
    "        \"verdict\": \"Likely successful\" if match_ratio>=0.50 else \"Likely to struggle\",\n",
    "        \"match_score\": round(match_ratio, 2),\n",
    "        \"risk_band\": risk,\n",
    "        \"requirements\": rows\n",
    "    }, f, indent=2)\n",
    "print(\"\\nSaved ->\", REPORTS / f\"06_final_verdict_hybrid_{ts}.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0eab16c5-f711-4977-80f7-d7813590f805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================\n",
      "CTE Character-Fit Verdict for Deo  |  (Hybrid∪LLM, min-traits, critical-guard)\n",
      "========================================================================\n",
      "Verdict: Likely to struggle ⚠️\n",
      "Overall: Not a fit   |   Match score: 0.29   |   Hiring risk: high-risk\n",
      "\n",
      "Required traits & match:\n",
      "trait\trequired_level\tcandidate_score\tmet\n",
      "independence\thigh\t0.65\tTrue\n",
      "communication\thigh\t0.3\tFalse\n",
      "curiosity\tmedium\t0.2\tFalse\n",
      "learning_mindset\tmedium\t0.6\tTrue\n",
      "focus\thigh\t0.45\tFalse\n",
      "planning\tmedium\t0.45\tFalse\n",
      "impact\tmedium\t0.35\tFalse\n",
      "\n",
      "Saved -> /Users/deo/UMKC_phd/project_related/job_related/cte-project/notebooks/reports/06_final_verdict_hardened_20251109_163340.json\n"
     ]
    }
   ],
   "source": [
    "# # ---- Cell 12 (hardened): Re-score with union requirements + critical-penalty ----\n",
    "# import json, datetime\n",
    "\n",
    "# # Load persona\n",
    "# with open(REPORTS/\"06_profile_persona_llm.json\") as f:\n",
    "#     persona = json.load(f)\n",
    "# per_trait = persona.get(\"per_trait\", {})\n",
    "\n",
    "# # 1) Union the two requirement sources (hybrid + LLM fallback from Cell 10)\n",
    "# def norm_level(s):\n",
    "#     s = (s or \"medium\").lower().strip()\n",
    "#     return s if s in {\"low\",\"medium\",\"high\"} else \"medium\"\n",
    "\n",
    "# seen = {}\n",
    "# def add_req(tr, lvl):\n",
    "#     tr = tr.strip().lower()\n",
    "#     if not tr: \n",
    "#         return\n",
    "#     lvl = norm_level(lvl)\n",
    "#     # keep the stricter of the two if duplicates (high > medium > low)\n",
    "#     rank = {\"low\":0, \"medium\":1, \"high\":2}\n",
    "#     if tr not in seen or rank[lvl] > rank[seen[tr]]:\n",
    "#         seen[tr] = lvl\n",
    "\n",
    "# # from Cell 11 (hybrid)\n",
    "# if 'requirements_hybrid' in globals() and requirements_hybrid:\n",
    "#     for r in requirements_hybrid:\n",
    "#         add_req(r.get(\"trait\",\"\"), r.get(\"required_level\",\"medium\"))\n",
    "\n",
    "# # from Cell 10 (LLM-only)\n",
    "# if 'requirements' in globals() and requirements:\n",
    "#     for r in requirements:\n",
    "#         add_req(r.get(\"trait\",\"\"), r.get(\"required_level\",\"medium\"))\n",
    "\n",
    "# # finalize list\n",
    "# reqs_union = [{\"trait\": t, \"required_level\": lvl} for t, lvl in seen.items()]\n",
    "\n",
    "# # 2) Enforce min trait count (expand with common DS behaviors if too few)\n",
    "# MIN_TRAITS = 5\n",
    "# COMMON_DS_FILLS = [\"planning\",\"focus\",\"reliability\",\"initiative\",\"teamwork\",\"communication\",\n",
    "#                    \"adaptability\",\"impact\",\"independence\",\"learning_mindset\",\"curiosity\",\"resilience\"]\n",
    "# for t in COMMON_DS_FILLS:\n",
    "#     if len(reqs_union) >= MIN_TRAITS: \n",
    "#         break\n",
    "#     if t not in {r[\"trait\"] for r in reqs_union}:\n",
    "#         # choose sensible default level\n",
    "#         lvl = \"medium\" if t not in {\"communication\",\"teamwork\",\"focus\",\"planning\"} else \"high\"\n",
    "#         reqs_union.append({\"trait\": t, \"required_level\": lvl})\n",
    "\n",
    "# # 3) Scoring knobs (stricter; adjust if you want looser)\n",
    "# LEVEL_THRESH = {\"low\": 0.50, \"medium\": 0.50, \"high\": 0.50}\n",
    "# LEVEL_WEIGHT = {\"low\": 1.0, \"medium\": 1.1, \"high\": 1.2}\n",
    "\n",
    "# # 4) Deterministic score\n",
    "# rows, total_w, met_w = [], 0.0, 0.0\n",
    "# unmet_high_criticals = []\n",
    "\n",
    "# CRITICAL_TRAITS = {\"communication\",\"teamwork\",\"focus\",\"reliability\",\"planning\"}\n",
    "# for r in reqs_union:\n",
    "#     t   = r[\"trait\"]\n",
    "#     lvl = r[\"required_level\"]\n",
    "#     if t not in per_trait: \n",
    "#         continue\n",
    "#     score = float(per_trait[t].get(\"score\", 0.0))\n",
    "#     thr   = LEVEL_THRESH[lvl]\n",
    "#     w     = LEVEL_WEIGHT[lvl]\n",
    "#     met   = score >= thr\n",
    "#     rows.append({\n",
    "#         \"trait\": t, \"required_level\": lvl,\n",
    "#         \"candidate_score\": round(score,2), \"threshold\": thr, \"met\": met\n",
    "#     })\n",
    "#     total_w += w\n",
    "#     if met: \n",
    "#         met_w += w\n",
    "#     if (not met) and (lvl == \"high\") and (t in CRITICAL_TRAITS):\n",
    "#         unmet_high_criticals.append(t)\n",
    "\n",
    "# if total_w == 0:\n",
    "#     total_w = 1.0\n",
    "\n",
    "# match_ratio = met_w / total_w\n",
    "\n",
    "# # 5) Base band from score\n",
    "# if   match_ratio >= 0.75: overall = \"Strong fit\";   risk = \"low-risk\"\n",
    "# elif match_ratio >= 0.50: overall = \"Possible fit\"; risk = \"moderate-risk\"\n",
    "# elif match_ratio >= 0.35: overall = \"Leaning no\";   risk = \"elevated-risk\"\n",
    "# else:                      overall = \"Not a fit\";    risk = \"high-risk\"\n",
    "\n",
    "# # 6) Downgrade one band if any critical high requirement is unmet\n",
    "# def downgrade(band):\n",
    "#     order = [\"Strong fit\",\"Possible fit\",\"Leaning no\",\"Not a fit\"]\n",
    "#     i = order.index(band)\n",
    "#     return order[min(i+1, len(order)-1)]\n",
    "\n",
    "# if unmet_high_criticals:\n",
    "#     overall = downgrade(overall)\n",
    "#     # adjust risk accordingly\n",
    "#     risk = {\"Strong fit\":\"low-risk\",\"Possible fit\":\"moderate-risk\",\"Leaning no\":\"elevated-risk\",\"Not a fit\":\"high-risk\"}[overall]\n",
    "\n",
    "# # 7) Pretty print\n",
    "# print(\"\\n\" + \"=\"*72)\n",
    "# print(\"CTE Character-Fit Verdict for Deo  |  (Hybrid∪LLM, min-traits, critical-guard)\")\n",
    "# print(\"=\"*72)\n",
    "# print(f\"Verdict: {'Likely successful ✅' if overall in ['Strong fit','Possible fit'] else 'Likely to struggle ⚠️'}\")\n",
    "# print(f\"Overall: {overall}   |   Match score: {match_ratio:.2f}   |   Hiring risk: {risk}\\n\")\n",
    "# print(\"Required traits & match:\")\n",
    "# print(\"trait\\trequired_level\\tcandidate_score\\tmet\")\n",
    "# for r in rows:\n",
    "#     print(f\"{r['trait']}\\t{r['required_level']}\\t{r['candidate_score']}\\t{r['met']}\")\n",
    "\n",
    "# # 8) Save compact JSON\n",
    "# ts = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "# with open(REPORTS / f\"06_final_verdict_hardened_{ts}.json\",\"w\") as f:\n",
    "#     json.dump({\n",
    "#         \"candidate\": \"Deo\",\n",
    "#         \"overall\": overall,\n",
    "#         \"verdict\": \"Likely successful\" if overall in [\"Strong fit\",\"Possible fit\"] else \"Likely to struggle\",\n",
    "#         \"match_score\": round(match_ratio, 2),\n",
    "#         \"risk_band\": risk,\n",
    "#         \"requirements\": rows,\n",
    "#         \"unmet_high_criticals\": unmet_high_criticals\n",
    "#     }, f, indent=2)\n",
    "# print(\"\\nSaved ->\", REPORTS / f\"06_final_verdict_hardened_{ts}.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02ba040-4b00-401a-80c9-1eb4017b806b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cte-project)",
   "language": "python",
   "name": "cte-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
