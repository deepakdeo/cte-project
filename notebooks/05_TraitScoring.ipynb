{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb767bf0-145a-4e93-b9f2-c552b2f694a0",
   "metadata": {},
   "source": [
    "# Trait Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07300d61-da7b-4675-b72f-295087d3316e",
   "metadata": {},
   "source": [
    "## 1) setup and load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a30f794-7771-40aa-909e-6a5fa6c07d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re, json, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Resolve project paths\n",
    "ROOT = Path.cwd()\n",
    "while not (ROOT/\"pyproject.toml\").exists() and ROOT.parent != ROOT:\n",
    "    ROOT = ROOT.parent\n",
    "DATA    = ROOT / \"data\" / \"interim\"\n",
    "REPORTS = ROOT / \"notebooks\" / \"reports\"\n",
    "FIGS    = REPORTS / \"figures\"\n",
    "for p in [REPORTS, FIGS]: p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FEATURES = DATA / \"features.parquet\"\n",
    "TARGET   = \"productivity_pct\"\n",
    "\n",
    "df = pd.read_parquet(FEATURES).sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "def clean_text(s):\n",
    "    if not isinstance(s, str): return \"\"\n",
    "    s = s.replace(\"\\n\",\" \").strip()\n",
    "    return re.sub(r\"\\s+\",\" \", s)\n",
    "\n",
    "ref = df.get(\"reflection\", pd.Series([\"\"]*len(df))).apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2405146-d87e-462b-a004-e1417e0a6fa1",
   "metadata": {},
   "source": [
    "## 2) Sentiment & subjectivity (VADER + TextBlob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "623c353a-48d4-487a-988f-1ca045c57337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entries': 72,\n",
       " 'avg_chars': 500,\n",
       " 'avg_sentiment': 0.45698749999999994,\n",
       " 'avg_subjectivity': 0.5060165258755894}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon', quiet=True)\n",
    "from textblob import TextBlob\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "df[\"refl_sent_compound\"] = ref.apply(lambda t: sia.polarity_scores(t)[\"compound\"])\n",
    "df[\"refl_subjectivity\"]  = ref.apply(lambda t: TextBlob(t).sentiment.subjectivity)\n",
    "\n",
    "# simple stats (for README/notes)\n",
    "refl_stats = {\n",
    "    \"entries\": int((ref.str.len()>0).sum()),\n",
    "    \"avg_chars\": int(ref.str.len().replace(0,np.nan).mean() or 0),\n",
    "    \"avg_sentiment\": float(df[\"refl_sent_compound\"].mean()),\n",
    "    \"avg_subjectivity\": float(df[\"refl_subjectivity\"].mean()),\n",
    "}\n",
    "refl_stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb1cd52-7d0b-4c64-af68-83867452a086",
   "metadata": {},
   "source": [
    "## 3) Keyword families → normalized “rates”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5e62060-f9d0-4a6e-81d4-780faa4ee553",
   "metadata": {},
   "outputs": [],
   "source": [
    "FAMS = {\n",
    "    \"planning\":   r\"\\b(plan|planned|schedule|prioriti[sz]e|milestone|deadline|timebox)\\b\",\n",
    "    \"blockers\":   r\"\\b(blocker|stuck|couldn'?t|issue|problem|delay|overwhelm|fatigue)\\b\",\n",
    "    \"learning\":   r\"\\b(learn|reading|paper|tutorial|experiment|tried|prototype|debug)\\b\",\n",
    "    \"collab\":     r\"\\b(team|sync|met|stakeholder|review|paired|helped|discuss)\\b\",\n",
    "    \"focus\":      r\"\\b(deep work|focus(ed)?|uninterrupted|flow|single[- ]task)\\b\",\n",
    "    \"wins\":       r\"\\b(done|finished|shipped|delivered|accomplish|achieved|progress)\\b\",\n",
    "}\n",
    "def count_regex(text, pat): return int(len(re.findall(pat, text.lower())))\n",
    "\n",
    "length = ref.str.len().replace(0, np.nan)\n",
    "for k,pat in FAMS.items():\n",
    "    cnt = ref.apply(lambda t: count_regex(t, pat))\n",
    "    df[f\"refl_{k}_count\"] = cnt\n",
    "    # rate per char, clipped\n",
    "    df[f\"refl_{k}_rate\"]  = (cnt/length).fillna(0).clip(0, 0.05)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6827741e-9dcf-4af2-a622-509ea2ec5f1d",
   "metadata": {},
   "source": [
    "## 4) Mini topics (unsupervised; optional if few entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1963032-b810-4a6c-8cdb-432c3eac8f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['topic_0:work, good, productive',\n",
       " 'topic_1:day, productive day, moving',\n",
       " 'topic_2:follow, plan, didn',\n",
       " 'topic_3:better, better tomorrow, help']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "docs = ref[ref.str.len()>0]\n",
    "topic_labels = []\n",
    "if len(docs) >= 10:\n",
    "    vec = TfidfVectorizer(min_df=2, max_df=0.9, ngram_range=(1,2), stop_words=\"english\")\n",
    "    X = vec.fit_transform(docs)\n",
    "    k = min(6, max(2, int(np.sqrt(X.shape[0])//2)))\n",
    "    nmf = NMF(n_components=k, random_state=42, init=\"nndsvd\", max_iter=500)\n",
    "    W = nmf.fit_transform(X); H = nmf.components_\n",
    "    terms = np.array(vec.get_feature_names_out())\n",
    "    # label topics\n",
    "    for i in range(k):\n",
    "        top = H[i].argsort()[-5:][::-1]\n",
    "        topic_labels.append(\"topic_\"+str(i)+\":\"+\", \".join(terms[top[:3]]))\n",
    "    # attach weights to df\n",
    "    W_df = pd.DataFrame(0.0, index=df.index, columns=[f\"refl_topic_{i}\" for i in range(k)])\n",
    "    W_df.loc[docs.index, :] = W\n",
    "    df = pd.concat([df, W_df], axis=1)\n",
    "\n",
    "topic_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e0e43a-9de0-4c7f-8fca-eaaf0ac08e6e",
   "metadata": {},
   "source": [
    "## 5) Text-derived traits (0–1) + save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2942420c-a15e-40d3-b5f6-712e3f09ab88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reflection_discipline': 1.0,\n",
       " 'resilience': 0.7277770593096825,\n",
       " 'planning_habit': 0.024520694114345584,\n",
       " 'curiosity_learning': 0.0012864621515077466,\n",
       " 'communication_collab': 0.0011453445866209705,\n",
       " 'focus_signals': 0.009538412983710812,\n",
       " 'delivery_orientation': 0.01614833044294438}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clip01(x): \n",
    "    x = float(x) if np.isfinite(x) else 0.0\n",
    "    return float(np.clip(x, 0, 1))\n",
    "\n",
    "reflect_freq   = ((ref.str.len()>0).mean())                          # 0..1\n",
    "reflect_len    = (ref.str.len().replace(0,np.nan).mean() or 0)/400.0 # ~400 chars → ~1.0\n",
    "pos_tone       = (df[\"refl_sent_compound\"].mean() + 1)/2              # [-1,1]→[0,1]\n",
    "\n",
    "traits_from_text = {\n",
    "    \"reflection_discipline\": clip01(0.6*reflect_freq + 0.4*reflect_len),\n",
    "    \"resilience\":            clip01( pos_tone * (1 - np.tanh(4*df[\"refl_blockers_rate\"].mean())) ),\n",
    "    \"planning_habit\":        clip01(df[\"refl_planning_rate\"].mean() * 20),\n",
    "    \"curiosity_learning\":    clip01(df[\"refl_learning_rate\"].mean() * 20),\n",
    "    \"communication_collab\":  clip01(df[\"refl_collab_rate\"].mean() * 20),\n",
    "    \"focus_signals\":         clip01(df[\"refl_focus_rate\"].mean() * 20),\n",
    "    \"delivery_orientation\":  clip01(df[\"refl_wins_rate\"].mean() * 20),\n",
    "}\n",
    "pd.Series(traits_from_text).to_csv(REPORTS/\"05_reflection_traits.csv\")\n",
    "traits_from_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f39326f-6e94-4e07-8903-118e118a580b",
   "metadata": {},
   "source": [
    "## 6) Load quantitative profile and combine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb15bac5-31f6-40db-8166-b08541e353d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/deo/UMKC_phd/project_related/job_related/cte-project/notebooks/reports/05_profile_traits_hybrid.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'communication_collab': 0.0011453445866209705,\n",
       " 'curiosity_learning': 0.0012864621515077466,\n",
       " 'delivery_orientation': 0.01614833044294438,\n",
       " 'focus_signals': 0.009538412983710812,\n",
       " 'planning_habit': 0.024520694114345584,\n",
       " 'reflection_discipline': 1.0,\n",
       " 'resilience': 0.7277770593096825}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you already saved a quant profile earlier as 05_profile_traits.csv\n",
    "quant_path = REPORTS/\"05_profile_traits.csv\"\n",
    "quant = pd.read_csv(quant_path, index_col=0).squeeze(\"columns\").to_dict() if quant_path.exists() else {}\n",
    "\n",
    "# Hybrid weighting (feel free to tweak)\n",
    "w_quant, w_text = 0.6, 0.4\n",
    "\n",
    "keys = sorted(set(quant) | set(traits_from_text))\n",
    "hybrid = {}\n",
    "for k in keys:\n",
    "    qv = float(quant.get(k, 0.0)); tv = float(traits_from_text.get(k, 0.0))\n",
    "    if k in quant and k in traits_from_text:\n",
    "        hybrid[k] = float(np.clip(w_quant*qv + w_text*tv, 0, 1))\n",
    "    else:\n",
    "        hybrid[k] = float(np.clip(qv or tv, 0, 1))\n",
    "\n",
    "pd.Series(hybrid).to_csv(REPORTS/\"05_profile_traits_hybrid.csv\")\n",
    "print(\"Saved:\", REPORTS/\"05_profile_traits_hybrid.csv\")\n",
    "hybrid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee5b9a1-21c4-4ea6-a91f-7dcd4ccf0dc2",
   "metadata": {},
   "source": [
    "## 7) JD → traits (keyword lexicon) + cosine match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73fed592-2760-4771-a206-7ad5c8345293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trait cosine match: 0.000\n"
     ]
    }
   ],
   "source": [
    "TRAIT_LEXICON = {\n",
    "    \"focus\": [\"focus\",\"deep work\",\"concentration\",\"attention\"],\n",
    "    \"reliability\": [\"reliable\",\"consistent\",\"ownership\",\"dependable\",\"on-time\"],\n",
    "    \"initiative\": [\"initiative\",\"proactive\",\"self-starter\",\"ownership\",\"drive\"],\n",
    "    \"communication\": [\"communication\",\"present\",\"explain\",\"stakeholder\",\"collaborate\",\"influence\"],\n",
    "    \"adaptability\": [\"adaptable\",\"flexible\",\"ambiguity\",\"fast-paced\",\"changing\"],\n",
    "    \"curiosity\": [\"curious\",\"question\",\"explore\",\"insight\",\"experimentation\"],\n",
    "    \"impact\": [\"impact\",\"value\",\"outcome\",\"deliver\",\"business\"],\n",
    "    \"teamwork\": [\"team\",\"cross-functional\",\"partner\",\"collaborate\"],\n",
    "    \"independence\": [\"independent\",\"autonomous\",\"self-driven\",\"ownership\"],\n",
    "    \"planning\": [\"plan\",\"prioritize\",\"roadmap\",\"deadline\",\"timebox\"],\n",
    "    \"resilience\": [\"resilience\",\"grit\",\"perseverance\",\"handle pressure\"],\n",
    "    \"learning_mindset\": [\"learn\",\"growth\",\"improve\",\"iterate\",\"feedback\"],\n",
    "}\n",
    "\n",
    "def jd_to_traits(jd_text: str, lexicon: dict) -> dict:\n",
    "    t = jd_text.lower()\n",
    "    scores = {k:0.0 for k in lexicon}\n",
    "    for trait, kws in lexicon.items():\n",
    "        s = 0\n",
    "        for kw in kws:\n",
    "            s += len(re.findall(rf\"\\b{re.escape(kw.lower())}\\b\", t))\n",
    "        scores[trait] = float(s)\n",
    "    mx = max(scores.values()) if scores else 1.0\n",
    "    if mx > 0:\n",
    "        for k in scores: scores[k] /= mx\n",
    "    return scores\n",
    "\n",
    "# Paste a real JD here when testing:\n",
    "JD_TEXT = \"\"\"\n",
    "We seek a proactive data scientist who communicates clearly with stakeholders,\n",
    "shows ownership, prioritizes well, and delivers business impact in a fast-paced environment.\n",
    "\"\"\"\n",
    "\n",
    "jd_traits = jd_to_traits(JD_TEXT, TRAIT_LEXICON)\n",
    "\n",
    "def cosine(a: dict, b: dict) -> float:\n",
    "    keys = sorted(set(a)&set(b))\n",
    "    va = np.array([a[k] for k in keys], float)\n",
    "    vb = np.array([b[k] for k in keys], float)\n",
    "    na, nb = np.linalg.norm(va), np.linalg.norm(vb)\n",
    "    return float(np.dot(va, vb)/(na*nb)) if na*nb>0 else 0.0\n",
    "\n",
    "match = cosine(hybrid, jd_traits)\n",
    "print(f\"Trait cosine match: {match:.3f}\")\n",
    "pd.Series(jd_traits).to_csv(REPORTS/\"05_jd_traits_demo.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd14eff-1433-44ff-82ec-875cea3dd822",
   "metadata": {},
   "source": [
    "## 8) Plots: JD vs You + contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "195073dc-847b-4e93-9ae6-86cafde4d310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: /Users/deo/UMKC_phd/project_related/job_related/cte-project/notebooks/reports/figures/05_trait_match_bars_hybrid.png\n",
      "Wrote: /Users/deo/UMKC_phd/project_related/job_related/cte-project/notebooks/reports/figures/05_trait_match_contrib_hybrid.png\n"
     ]
    }
   ],
   "source": [
    "# Bars: JD (top traits) vs You\n",
    "pairs = sorted(jd_traits.items(), key=lambda kv: kv[1], reverse=True)[:10]\n",
    "traits = [k for k,_ in pairs]\n",
    "jdv = [jd_traits[k] for k in traits]\n",
    "mev = [hybrid.get(k,0) for k in traits]\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "idx = np.arange(len(traits)); w=0.4\n",
    "plt.bar(idx-w/2, jdv, width=w, label=\"JD\")\n",
    "plt.bar(idx+w/2, mev, width=w, label=\"You\")\n",
    "plt.xticks(idx, traits, rotation=30, ha=\"right\")\n",
    "plt.ylim(0,1)\n",
    "plt.title(f\"Trait match (cosine={match:.2f}) — Hybrid profile\")\n",
    "plt.legend()\n",
    "out = FIGS/\"05_trait_match_bars_hybrid.png\"\n",
    "plt.tight_layout(); plt.savefig(out, dpi=150); plt.close(); print(\"Wrote:\", out)\n",
    "\n",
    "# Contribution = elementwise product\n",
    "contrib = [(t, hybrid.get(t,0)*jd_traits.get(t,0)) for t in traits]\n",
    "contrib.sort(key=lambda x: x[1], reverse=True)\n",
    "plt.figure(figsize=(7,4.5))\n",
    "plt.barh([t for t,_ in contrib[::-1]], [v for _,v in contrib[::-1]])\n",
    "plt.xlabel(\"Contribution (my_score × jd_weight)\")\n",
    "plt.title(\"Per-trait contribution to match (Top JD traits)\")\n",
    "out = FIGS/\"05_trait_match_contrib_hybrid.png\"\n",
    "plt.tight_layout(); plt.savefig(out, dpi=150); plt.close(); print(\"Wrote:\", out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6effbb5-9a88-4caf-b4a4-9c38cfec988d",
   "metadata": {},
   "source": [
    "## 9) Optional GenAI verdict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b037526-2505-495e-bed9-018dcd0ba3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved verdict: /Users/deo/UMKC_phd/project_related/job_related/cte-project/notebooks/reports/05_trait_fit_verdict_hybrid.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'overall_fit': 'Not a fit',\n",
       " 'match_score': 0.0,\n",
       " 'top_strengths': ['focus',\n",
       "  'reliability',\n",
       "  'initiative',\n",
       "  'communication',\n",
       "  'adaptability'],\n",
       " 'top_gaps': ['initiative', 'impact', 'reliability'],\n",
       " 'evidence': ['focus: mine=0.00, jd=0.00',\n",
       "  'reliability: mine=0.00, jd=0.50',\n",
       "  'initiative: mine=0.00, jd=1.00',\n",
       "  'communication: mine=0.00, jd=0.00',\n",
       "  'adaptability: mine=0.00, jd=0.50'],\n",
       " 'suggested_actions': [\"Raise 'initiative' via targeted habits/projects over 2–4 weeks.\",\n",
       "  \"Raise 'impact' via targeted habits/projects over 2–4 weeks.\",\n",
       "  \"Raise 'reliability' via targeted habits/projects over 2–4 weeks.\"]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FIT_SCHEMA = {\n",
    "  \"type\":\"object\",\n",
    "  \"properties\":{\n",
    "    \"overall_fit\":{\"type\":\"string\",\"enum\":[\"Strong fit\",\"Possible fit\",\"Borderline\",\"Not a fit\"]},\n",
    "    \"match_score\":{\"type\":\"number\"},\n",
    "    \"top_strengths\":{\"type\":\"array\",\"items\":{\"type\":\"string\"}},\n",
    "    \"top_gaps\":{\"type\":\"array\",\"items\":{\"type\":\"string\"}},\n",
    "    \"evidence\":{\"type\":\"array\",\"items\":{\"type\":\"string\"}},\n",
    "    \"suggested_actions\":{\"type\":\"array\",\"items\":{\"type\":\"string\"}}\n",
    "  },\n",
    "  \"required\":[\"overall_fit\",\"match_score\",\"top_strengths\",\"top_gaps\",\"evidence\",\"suggested_actions\"]\n",
    "}\n",
    "\n",
    "def call_llm(system: str, user: str, model=\"gpt-4.1-mini\"):\n",
    "    # TODO: replace with your provider call; must return text\n",
    "    raise RuntimeError(\"Wire your LLM provider here.\")\n",
    "\n",
    "# pick a few short quotes as evidence (optional)\n",
    "examples = []\n",
    "pos = df.sort_values(\"refl_sent_compound\", ascending=False)\n",
    "neg = df.sort_values(\"refl_sent_compound\", ascending=True)\n",
    "for i,row in pos.head(3).iterrows():\n",
    "    t = clean_text(row.get(\"reflection\",\"\"))\n",
    "    if t: examples.append(f\"POS[{str(row['date'])[:10]}]: {t[:140]}\")\n",
    "for i,row in neg.head(2).iterrows():\n",
    "    t = clean_text(row.get(\"reflection\",\"\"))\n",
    "    if t: examples.append(f\"CHALLENGE[{str(row['date'])[:10]}]: {t[:140]}\")\n",
    "evidence_quotes = examples[:5]\n",
    "\n",
    "system_msg = (\n",
    " \"You are a precise hiring analyst. Use ONLY the numeric trait vectors and match score. \"\n",
    " \"Return STRICT JSON conforming to the given schema. Be concise and concrete.\"\n",
    ")\n",
    "user_msg = f\"\"\"\n",
    "Hybrid profile (0-1): {json.dumps(hybrid, indent=2)}\n",
    "JD trait weights (0-1): {json.dumps(jd_traits, indent=2)}\n",
    "cosine_match: {match:.3f}\n",
    "Evidence quotes (optional): {json.dumps(evidence_quotes, indent=2)}\n",
    "Schema: {json.dumps(FIT_SCHEMA, indent=2)}\n",
    "\"\"\"\n",
    "\n",
    "def judge_fit(system_msg, user_msg):\n",
    "    try:\n",
    "        text = call_llm(system_msg, user_msg)\n",
    "        try:\n",
    "            return json.loads(text)\n",
    "        except Exception:\n",
    "            import re\n",
    "            m = re.search(r\"\\{.*\\}\", text, re.S)\n",
    "            return json.loads(m.group(0)) if m else {}\n",
    "    except RuntimeError:\n",
    "        # Fallback numeric verdict (works without API)\n",
    "        top_gaps = sorted(jd_traits, key=lambda k: jd_traits[k]-hybrid.get(k,0), reverse=True)[:3]\n",
    "        top_strengths = sorted(jd_traits, key=lambda k: hybrid.get(k,0)*jd_traits[k], reverse=True)[:5]\n",
    "        overall = \"Strong fit\" if match>=0.7 else \"Possible fit\" if match>=0.55 else \"Borderline\" if match>=0.45 else \"Not a fit\"\n",
    "        return {\n",
    "          \"overall_fit\": overall,\n",
    "          \"match_score\": round(match,3),\n",
    "          \"top_strengths\": top_strengths,\n",
    "          \"top_gaps\": top_gaps,\n",
    "          \"evidence\": [f\"{k}: mine={hybrid.get(k,0):.2f}, jd={jd_traits[k]:.2f}\" for k in top_strengths],\n",
    "          \"suggested_actions\": [f\"Raise '{g}' via targeted habits/projects over 2–4 weeks.\" for g in top_gaps]\n",
    "        }\n",
    "\n",
    "verdict = judge_fit(system_msg, user_msg)\n",
    "with open(REPORTS/\"05_trait_fit_verdict_hybrid.json\",\"w\") as f:\n",
    "    json.dump(verdict, f, indent=2)\n",
    "print(\"Saved verdict:\", REPORTS/\"05_trait_fit_verdict_hybrid.json\")\n",
    "verdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b358bc27-47d2-4219-aec7-a1cee280f46a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cte-project)",
   "language": "python",
   "name": "cte-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
